{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChitranshS/HiringChallenge-1/blob/main/Hiring_Challenge_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we have to check whether we are connected to the right runtime or not.\n",
        "## Please connect to the T4 runtime before moving ahead.\n",
        "I will also add the instructions to the github as well"
      ],
      "metadata": {
        "id": "4qg7o9fYmlzr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP9FjmWxtLKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707f8846-680a-4adc-8d7e-67a9d1c148b5",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-9217c8fc-684c-494a-34e4-afc475040a44)\n"
          ]
        }
      ],
      "source": [
        "#@title GPU available?\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We need to download approx 5-6 GBs in this step\n",
        "The next step will take some while as we need to download a whole bunch of libraries in a single go.\n"
      ],
      "metadata": {
        "id": "7khJb9QwmVQZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpPKQR40qvz2",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Initial Library Setup\n",
        "import os, subprocess\n",
        "\n",
        "def setup():\n",
        "    install_cmds = [\n",
        "        ['pip', 'install', 'gradio'],\n",
        "        ['pip', 'install', 'open_clip_torch'],\n",
        "        ['pip', 'install', 'clip-interrogator'],\n",
        "        ['pip', 'install', 'together'],\n",
        "        ['pip','install','gradio_client'],\n",
        "        ['pip','install','pytesseract']\n",
        "    ]\n",
        "    for cmd in install_cmds:\n",
        "        print(subprocess.run(cmd, stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "\n",
        "setup()\n",
        "\n",
        "import gradio as gr\n",
        "from clip_interrogator import Config, Interrogator\n",
        "\n",
        "config = Config()\n",
        "config.clip_model_name = 'ViT-H-14/laion2b_s32b_b79k'  # Default clip model\n",
        "config.caption_model_name = 'blip-large'  # Default caption model\n",
        "ci = Interrogator(config)\n",
        "os.mkdir(\"/content/uploads\")\n",
        "os.mkdir(\"/content/augment\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title CLIP Implementation\n",
        "def image_to_prompt(image):\n",
        "    ci.config.chunk_size =1024\n",
        "    ci.config.flavor_intermediate_count =1024\n",
        "    # ci.config.flavor_intermediate_count = 2048 if ci.config.clip_model_name == \"ViT-L-14/openai\" else 1024\n",
        "    image = image.convert('RGB')\n",
        "    modes = ['best','fast','normal']\n",
        "    mode = random.choice(modes)  # Set mode to 'fast' by default\n",
        "    generated_prompt = ci.interrogate_fast(image)\n",
        "    return generated_prompt\n"
      ],
      "metadata": {
        "id": "MR5U5Bw0vnHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf6qkFG6MPRj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "3b707a1d-75ab-4e6a-b712-6a5de5dcb89e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://f7c2594d60e9d82bd6.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f7c2594d60e9d82bd6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Upload Image (PNG/JPEG only for now)\n",
        "import gradio as gr\n",
        "\n",
        "def prompt_tab():\n",
        "    global stored_prompt  # Declare the stored_prompt variable as global\n",
        "\n",
        "    with gr.Column():\n",
        "        with gr.Row():\n",
        "            print(1)\n",
        "            image = gr.Image(type='pil', label=\"Image\")\n",
        "            print(2)\n",
        "        prompt = gr.Textbox(label=\"Prompt\")\n",
        "        print(3)\n",
        "        button = gr.Button(\"Generate prompt\")\n",
        "        print(4)\n",
        "        button.click(image_to_prompt, inputs=[image], outputs=[prompt])\n",
        "        print(5)\n",
        "\n",
        "            # Store the prompt value after rendering\n",
        "        prompt.change(update_stored_prompt, inputs=[prompt], outputs=[])\n",
        "\n",
        "\n",
        "def update_stored_prompt(prompt):\n",
        "    global stored_prompt\n",
        "    stored_prompt = prompt  # Assign the prompt value to the stored_prompt variable\n",
        "\n",
        "with gr.Blocks() as ui:\n",
        "    with gr.Tab(\"Prompt\"):\n",
        "        stored_prompt = \"\"  # Initialize the stored_prompt variable\n",
        "        prompt_tab()\n",
        "    ui.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGmvkzITN4Hz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6947854c-ef48-4e0b-b8b9-0859013a8afc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a close up of a diamond ring with a diamond band, hexagonal ring, “diamonds, centered thin ring iris, h 576, magic ring with a diamond, diamond and rose quartz, alp, h 768, h 7 6 8, engineered, # e 5 3 7 1 b, ƒ/5.6, elden ring style'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 586
        }
      ],
      "source": [
        "stored_prompt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \" Shutter Camera,Film,DSLR\""
      ],
      "metadata": {
        "id": "HtLwdorWAKXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Dynamic Prompt\n",
        "import os\n",
        "import random\n",
        "import together\n",
        "\n",
        "together.api_key = \"\"\n",
        "response = together.Complete.create(\n",
        "    model=\"meta-llama/Llama-3-70b-chat-hf\",\n",
        "    prompt=f\"\"\"ONLY REPLY AFTER READING THE ENTIRE TEXT NOT BEFORE THAT.THIS IS NOT A CONVERSATION.REPLY AS IF YOU HAVE TO A API CALL EXPECTING A NON CONVERSATIVE ANSWER.I will give you a product description i.e. {stored_prompt}\n",
        "    Identify entities which will look appealing and aesthetic in a marketing campaign studio where the product  is :{user_prompt}\n",
        "    Now your task is to generate keywords from this and {user_prompt} which are related to the product and can be used in its marketing.\n",
        "    ONLY GIVE THE PROMPT TEXT NOTHING ELSE. THE PROMPT SHOULD BE COMPLETE AND LESS THAN 50 WORDS. DON'T REPEAT THE PROMPT IN A SINGLE REPLY. STOP AND LEAVE BLANK SPACES WHEN THE PROMPT IS OVER. DO NOT USE '\\n' AND OTHER MARKDOWN \"\"\",\n",
        "    temperature = round(random.uniform(1, 2),1),\n",
        "    top_k = 50,\n",
        "    max_tokens = 300,\n",
        "    top_p = 0.7,\n",
        "    repetition_penalty = 1\n",
        ")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqSUyV0clJvd",
        "outputId": "e049ced4-5044-4029-cbdc-d470dbdb47cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-678-557a96e74890>:7: DeprecationWarning: Call to deprecated function create.\n",
            "  response = together.Complete.create(\n",
            "/usr/local/lib/python3.10/dist-packages/together/legacy/complete.py:23: UserWarning: The use of together.api_key is deprecated and will be removed in the next major release. Please set the TOGETHER_API_KEY environment variable instead.\n",
            "  warnings.warn(API_KEY_WARNING)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '87a2ae861e3a6039-SIN', 'object': <ObjectType.Completion: 'text.completion'>, 'created': 1714093712, 'model': 'meta-llama/Llama-3-70b-chat-hf', 'choices': [{'index': 0, 'logprobs': None, 'finish_reason': <FinishReason.Length: 'length'>, 'text': \" AND HTML TAGS AND DO NOT LEAVE YOUR OWN OPINION.  JUST PROVIDE THE KEYWORDS.\\n\\n\\ncamera \\nlens \\nblack \\nbackground \\n80s \\n35mm \\nfilm \\nmedium \\nformat \\ntri \\nx \\npan \\nstock \\nphoto \\nrealistic \\nnikon \\nmamiya \\nShutter \\nCamera \\nFilm \\nDSLR \\nbeach \\n\\ncamera lens \\nfilm camera \\nmedium format camera \\n35mm film camera \\ndslr camera \\nbeach camera \\nfilm photography \\ncamera photography \\nphotography studio \\nbeach photography \\nfilm camera style \\nretro camera \\nvintage camera \\nanalog camera \\nclassic camera \\nold camera \\nphotography equipment \\ncamera accessories \\nfilm stock \\nphotography props \\nbeach props \\nphotography studio props \\nfilm camera accessories \\nvintage photography \\nretro photography \\nanalog photography \\nclassic photography \\nold photography \\nphotography tools \\ncamera tools \\nfilm tools \\nbeach tools \\nphotography studio tools \\nfilm camera tools \\nvintage photography tools \\nretro photography tools \\nanalog photography tools \\nclassic photography tools \\nold photography toolsassistant\\n\\n \\n\\n\\n\\nassistant\\n\\nI'll provide the keywords. Here they are:\\n\\ncamera \\nlens \\nblack \\nbackground \\n80s \\n35mm \\nfilm \\nmedium \\nformat \\ntri \\nx \\npan \\nstock \\nphoto \\nrealistic \\nnikon \\nmamiya \\nShutter \\nCamera \\nFilm \\nDSLR \\nbeach\"}], 'prompt': [], 'usage': {'prompt_tokens': 263, 'completion_tokens': 300, 'total_tokens': 563}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_prompt = response['choices'][0]\n",
        "generation_prompt"
      ],
      "metadata": {
        "id": "dzWaa8hq4nWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2940189-ada3-4f9e-b883-3aedb471b333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'index': 0,\n",
              " 'logprobs': None,\n",
              " 'finish_reason': <FinishReason.Length: 'length'>,\n",
              " 'text': \" AND HTML TAGS AND DO NOT LEAVE YOUR OWN OPINION.  JUST PROVIDE THE KEYWORDS.\\n\\n\\ncamera \\nlens \\nblack \\nbackground \\n80s \\n35mm \\nfilm \\nmedium \\nformat \\ntri \\nx \\npan \\nstock \\nphoto \\nrealistic \\nnikon \\nmamiya \\nShutter \\nCamera \\nFilm \\nDSLR \\nbeach \\n\\ncamera lens \\nfilm camera \\nmedium format camera \\n35mm film camera \\ndslr camera \\nbeach camera \\nfilm photography \\ncamera photography \\nphotography studio \\nbeach photography \\nfilm camera style \\nretro camera \\nvintage camera \\nanalog camera \\nclassic camera \\nold camera \\nphotography equipment \\ncamera accessories \\nfilm stock \\nphotography props \\nbeach props \\nphotography studio props \\nfilm camera accessories \\nvintage photography \\nretro photography \\nanalog photography \\nclassic photography \\nold photography \\nphotography tools \\ncamera tools \\nfilm tools \\nbeach tools \\nphotography studio tools \\nfilm camera tools \\nvintage photography tools \\nretro photography tools \\nanalog photography tools \\nclassic photography tools \\nold photography toolsassistant\\n\\n \\n\\n\\n\\nassistant\\n\\nI'll provide the keywords. Here they are:\\n\\ncamera \\nlens \\nblack \\nbackground \\n80s \\n35mm \\nfilm \\nmedium \\nformat \\ntri \\nx \\npan \\nstock \\nphoto \\nrealistic \\nnikon \\nmamiya \\nShutter \\nCamera \\nFilm \\nDSLR \\nbeach\"}"
            ]
          },
          "metadata": {},
          "execution_count": 679
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gradio_client"
      ],
      "metadata": {
        "id": "WO-Ngn9V_WTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # !pip install pytesseract\n",
        "# round(random.uniform(1, 2),1)"
      ],
      "metadata": {
        "id": "zPgm50UoS4Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install Tesseract\n",
        "# !sudo apt install tesseract-ocr\n",
        "\n",
        "# # Install pytesseract, a Python wrapper for Tesseract\n",
        "# !pip install pytesseract\n"
      ],
      "metadata": {
        "id": "jtiqDin_T4-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pytesseract\n",
        "# from PIL import Image\n",
        "# import numpy as np\n",
        "# import cv2\n",
        "# import matplotlib.pyplot as plt\n",
        "# imageSent = Image.open('/content/uploads/product3.png')\n",
        "# image_cv = np.array(imageSent)\n",
        "\n",
        "# # Convert RGB to BGR (OpenCV uses BGR by default)\n",
        "\n",
        "# # Apply Canny edge detection\n",
        "# edges = cv2.Canny(image_cv, 100, 1100)  # These thresholds can be adjusted\n",
        "\n",
        "# # Convert back to PIL image to use any PIL functionalities further or just display using matplotlib\n",
        "# edges_image = Image.fromarray(edges)\n",
        "# extracted_text = pytesseract.image_to_string(edges)\n",
        "# plt.imshow(edges_image)\n",
        "# print(extracted_text)"
      ],
      "metadata": {
        "id": "2PS8pnOKS3gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change this number as per the product{number}\n"
      ],
      "metadata": {
        "id": "xzPhDfCj92Xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number = 1"
      ],
      "metadata": {
        "id": "m5xZzGH8jAWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Product Background\n",
        "from gradio_client import Client\n",
        "\n",
        "client = Client(\"https://hysts-controlnet-v1-1.hf.space/\")\n",
        "imageSent = Image.open(f'/content/uploads/product{number}.png')\n",
        "rotated_image = imageSent.rotate(random.uniform(-10,10))\n",
        "# rotated_image = imageSent.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "save_path = f'/content/augment/product{number}.png'  # Replace with your output file path and desired format\n",
        "rotated_image.save(save_path, 'PNG')\n",
        "\n",
        "result = client.predict(\n",
        "\t\tf\"/content/augment/product{number}.png\",\t# str (filepath on your computer (or URL) of image) in 'parameter_8' Image component\n",
        "\t\tgeneration_prompt,\t# str  in 'Prompt' Textbox component\n",
        "\t\tf\"best quality, extremely detailed , {user_prompt}, Marketing , Product photography, enhanced , Multiple angles\",\t# str  in 'Additional prompt' Textbox component\n",
        "\t\t\"longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality,dull colours\",\t# str  in 'Negative prompt' Textbox component\n",
        "\t\t1,\t# int | float (numeric value between 1 and 1) in 'Number of images' Slider component\n",
        "\t\t720.00,\t# int | float (numeric value between 256 and 768) in 'Image resolution' Slider component\n",
        "\t\trandom.randint(30,96),\t# int | float (numeric value between 1 and 100) in 'Number of steps' Slider component\n",
        "\t\tround(random.uniform(10,28),1),\t# int | float (numeric value between 0.1 and 30.0) in 'Guidance scale' Slider component\n",
        "\t\trandom.randint(0,2232232),\t# int | float (numeric value between 0 and 2147483647) in 'Seed' Slider component\n",
        "\t\t50,\t# int | float (numeric value between 1 and 255) in 'Canny low threshold' Slider component\n",
        "\t\t200,\t# int | float (numeric value between 1 and 255) in 'Canny high threshold' Slider component\n",
        "\t\tapi_name=\"/canny\"\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVrMKZzL5i0u",
        "outputId": "ef4e03cd-5314-437c-ea42-8f287b63fe4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: https://hysts-controlnet-v1-1.hf.space/ ✔\n",
            "/tmp/gradio/e603a20c-c18f-42de-8900-f53d8c1ee399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirpath, dirnames, filenames in os.walk(result):\n",
        "  if dirnames:\n",
        "   directories = dirnames\n",
        "   break\n",
        "result"
      ],
      "metadata": {
        "id": "3y6JRMoUJGys",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "64ba4a92-aba3-4ecb-e338-de4692c397ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/tmp/gradio/e603a20c-c18f-42de-8900-f53d8c1ee399'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 686
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Image Resizing\n",
        "from PIL import Image\n",
        "\n",
        "# Load the image\n",
        "imageResize = Image.open(f'../content/augment/product{number}.png')\n",
        "background1 = Image.open(f'../{result}/{directories[0]}/image.png')\n",
        "\n",
        "\n",
        "# Specify the new dimensions\n",
        "new_width , new_height = background1.size\n",
        "\n",
        "# Resize the image\n",
        "resized_image = imageResize.resize((new_width, new_height), Image.LANCZOS)\n",
        "\n",
        "# Save the resized image\n",
        "resized_image.save('resized_image.png')\n",
        "\n",
        "# Display the resized image (optional)\n",
        "resized_image.show()\n"
      ],
      "metadata": {
        "id": "JmheT_fCF4Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Using the generated image and the mask\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# Open the background and overlay images\n",
        "background1 = Image.open(f'../{result}/{directories[0]}/image.png')\n",
        "background2 = Image.open(f'../{result}/{directories[1]}/image.png')\n",
        "overlay = Image.open('../content/resized_image.png')\n",
        "\n",
        "# You might need to resize the overlay or use it as is, depending on the need\n",
        "# For example, resize overlay to match background's size\n",
        "# overlay = overlay.resize(background.size, Image.ANTIALIAS)\n",
        "print(\"Background mode:\", background1.mode)\n",
        "print(\"Background mode:\", background2.mode)\n",
        "print(\"Overlay mode:\", overlay.mode)\n",
        "# Position the overlay at the desired position (top-left corner in this example)\n",
        "# You can change (0, 0) to whatever coordinates you want\n",
        "position = (0, 0)  # Position can be changed based on where you want to place the overlay\n",
        "if background1.mode != 'RGBA':\n",
        "    background = background1.convert('RGBA')\n",
        "if background2.mode != 'RGBA':\n",
        "    background = background2.convert('RGBA')\n",
        "if overlay.mode != 'RGBA':\n",
        "    overlay = overlay.convert('RGBA')\n",
        "# Assuming both images are now RGBA\n",
        "# Extract the alpha channel from the overlay\n",
        "alpha_mask = overlay.split()[3]\n",
        "\n",
        "# Paste the overlay using the alpha channel as a mask\n",
        "background1.paste(overlay, (0, 0), alpha_mask)  # Adjust position as needed\n",
        "\n",
        "# Save or show the result\n",
        "background1.save('output_image1.png')  # Save as PNG to preserve transparency in the output\n",
        "background1.show()\n",
        "\n",
        "background2.paste(overlay, (0, 0), alpha_mask)  # Adjust position as needed\n",
        "\n",
        "# Save or show the result\n",
        "background2.save('output_image2.png')  # Save as PNG to preserve transparency in the output\n",
        "background2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k520KejN_hI6",
        "outputId": "4e1c7e9c-bb51-4ffe-8517-059d313fb092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Background mode: RGB\n",
            "Background mode: RGB\n",
            "Overlay mode: RGBA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c5QZkOoGDC84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now two images will be there output_image1.png and output_image2.png\n",
        "One of them is the canny mask and other is the final product."
      ],
      "metadata": {
        "id": "BuL2wsY19_bw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vQv4pLW0SzS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U4X-d8oREcC5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1f51d5616d3bc2b87a82685314c5be1ec9a49b6e0cb1f707bfa2acb6c45f3e5f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
